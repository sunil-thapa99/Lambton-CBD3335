{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write a python program to compute the sum of the two reversed numbers and display the sum in reversed form.\n",
    "Input: 13, 14\n",
    "Output: 27\n",
    "Note: The result will not be unique for every number for example 31 is a reversed form of several numbers of 13, 130, 1300 etc.\n",
    "Therefore all the leading zeros will be omitted. \n",
    "'''\n",
    "def sum_reverse_number(num1: int, num2: int) -> int:\n",
    "    num1 = int(str(num1)[::-1])\n",
    "    num2 = int(str(num2)[::-1])\n",
    "    return int(str(num1+num2)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_reverse_number(13, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_reverse_number(15, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_reverse_number(1300, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Write a python program to check whether a given number is an ugly number\n",
    "Input: 12\n",
    "Output: True\n",
    "Ugly numbers are positive numbers whose only prime factors are 2, 3, or 5.\n",
    "The sequence 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, ....\n",
    "Note: 1 is typically treated as an ugly number\n",
    "'''\n",
    "def is_ugly(num: int) -> bool:\n",
    "    if num <= 0:\n",
    "        return False\n",
    "    elif num == 1:\n",
    "        return True\n",
    "    factor = [2, 3, 5]\n",
    "    for i in factor:\n",
    "        while num%i == 0:\n",
    "            num /= i\n",
    "    return num == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_ugly(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_ugly(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Can you please buy me an Arizona Ice Tea? It is $0.99.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "token = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Can',\n",
       " 'you',\n",
       " 'please',\n",
       " 'buy',\n",
       " 'me',\n",
       " 'an',\n",
       " 'Arizona',\n",
       " 'Ice',\n",
       " 'Tea',\n",
       " '?',\n",
       " 'It',\n",
       " 'is',\n",
       " '$',\n",
       " '0.99',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parts of the speech: [('Can', 'MD'), ('you', 'PRP'), ('please', 'VB'), ('buy', 'VB'), ('me', 'PRP'), ('an', 'DT'), ('Arizona', 'NNP'), ('Ice', 'NNP'), ('Tea', 'NNP'), ('?', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('$', '$'), ('0.99', 'CD'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# https://www.guru99.com/pos-tagging-chunking-nltk.html#:~:text=Summary,each%20word%20of%20the%20sentence.\n",
    "print(f\"parts of the speech: {nltk.pos_tag(token)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = np.array(['I love Brazil. Brazil!', 'Sweden is best', 'Germany beats both'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beats', 'best', 'both', 'brazil', 'germany', 'is', 'love', 'sweden']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(bag_of_words.toarray(), columns=count.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beats</th>\n",
       "      <th>best</th>\n",
       "      <th>both</th>\n",
       "      <th>brazil</th>\n",
       "      <th>germany</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sweden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beats  best  both  brazil  germany  is  love  sweden\n",
       "0      0     0     0       2        0   0     1       0\n",
       "1      0     1     0       0        0   1     0       1\n",
       "2      1     0     1       0        1   0     0       0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.89442719, 0.        ,\n",
       "        0.        , 0.4472136 , 0.        ],\n",
       "       [0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.57735027],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beats</th>\n",
       "      <th>best</th>\n",
       "      <th>both</th>\n",
       "      <th>brazil</th>\n",
       "      <th>germany</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sweden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     beats     best     both    brazil  germany       is      love   sweden\n",
       "0  0.00000  0.00000  0.00000  0.894427  0.00000  0.00000  0.447214  0.00000\n",
       "1  0.00000  0.57735  0.00000  0.000000  0.00000  0.57735  0.000000  0.57735\n",
       "2  0.57735  0.00000  0.57735  0.000000  0.57735  0.00000  0.000000  0.00000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(feature_matrix.toarray(), columns=tfidf.get_feature_names())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 6,\n",
       " 'brazil': 3,\n",
       " 'sweden': 7,\n",
       " 'is': 5,\n",
       " 'best': 1,\n",
       " 'germany': 4,\n",
       " 'beats': 0,\n",
       " 'both': 2}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word index for toarray()\n",
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.89442719, 0.        ,\n",
       "        0.        , 0.4472136 , 0.        ],\n",
       "       [0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.57735027],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.toarray()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In class Assignment-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'Feature Extraction aims to reduce the number of features in a dataset by creating new features from the existing ones (and then discarding the original features). These new reduced set of features should then be able to summarize most of the information contained in the original set of features!!!. In this way, a summarised version of the original features can be created from a combination of the original set!!!'\n",
    "text2 = 'Another commonly used technique to reduce the number of feature in a dataset is Feature Selection! The difference between Feature Selection and/or Feature Extraction is that feature selection aims instead to $ rank the importance of the existing features in the dataset and discard less important ones (no new features are created)?!. If you are interested in finding out more about Feature Selection, you can find more information about it in my previous article.'\n",
    "text3 = 'In this article, I will walk you through how to apply Feature Extraction techniques using the Kaggle Mushroom Classification Dataset as an example??? Our objective will be to try to predict if a Mushroom is poisonous or not by looking at the given features. All the code used in this post (and more!) is available on Kaggle and on my GitHub Account.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# remove punctuation from text\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = remove_punctuation(text1)\n",
    "text2 = remove_punctuation(text2)\n",
    "text3 = remove_punctuation(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_tokenize = word_tokenize(text1)\n",
    "text2_tokenize = word_tokenize(text2)\n",
    "text3_tokenize = word_tokenize(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwods from text\n",
    "def remove_stopwords(text: list) -> list:\n",
    "    text_list = [word for word in text if word.lower() not in stopwords]\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_stopwords = remove_stopwords(text1_tokenize)\n",
    "text2_stopwords = remove_stopwords(text2_tokenize)\n",
    "text3_stopwords = remove_stopwords(text3_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem  import PorterStemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmize(text_list: list) -> list:\n",
    "    new_text_list = []\n",
    "    for word in text_list:\n",
    "        word = word.lower()\n",
    "        new_text_list.append(porter.stem(word))\n",
    "\n",
    "    return new_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_stem = stemmize(text1_stopwords)\n",
    "text2_stem = stemmize(text2_stopwords)\n",
    "text3_stem = stemmize(text3_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tag(text_list: list) -> list:\n",
    "    return nltk.pos_tag(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_pos = get_pos_tag(text1_stopwords)\n",
    "text2_pos = get_pos_tag(text2_stopwords)\n",
    "text3_pos = get_pos_tag(text3_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_pos_lemmetize(text_list: list) -> list:\n",
    "    new_lemmetize_list = []\n",
    "    for text, tag in text_list:\n",
    "        text = text.lower()\n",
    "        if tag.startswith('N'):\n",
    "            wld = word_lem.lemmatize(text, pos='n')\n",
    "        elif tag.startswith('V'):\n",
    "            wld = word_lem.lemmatize(text, pos='v')\n",
    "        elif tag.startswith('J'):\n",
    "            wld = word_lem.lemmatize(text, pos='a')\n",
    "        elif tag.startswith('R'):\n",
    "            wld = word_lem.lemmatize(text, pos='r')\n",
    "        else:\n",
    "            wld = text\n",
    "        new_lemmetize_list.append(wld)\n",
    "    return new_lemmetize_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_lem = word_pos_lemmetize(text1_pos)\n",
    "text2_lem = word_pos_lemmetize(text2_pos)\n",
    "text3_lem = word_pos_lemmetize(text3_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_to_str(text_list: list) -> str:\n",
    "    str_text = ''\n",
    "    for i in text_list:\n",
    "        str_text += i +' '\n",
    "    return str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_text1 = convert_list_to_str(text1_lem)\n",
    "str_text2 = convert_list_to_str(text2_lem)\n",
    "str_text3 = convert_list_to_str(text3_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['feature extraction aim reduce number feature dataset create new feature exist one discard original feature new reduce set feature able summarize information contain original set feature way summarise version original feature create combination original set ',\n",
       "       'another commonly use technique reduce number feature dataset feature selection difference feature selection andor feature extraction feature selection aim instead rank importance exist feature dataset discard less important one new feature create interested finding feature selection find information previous article ',\n",
       "       'article walk apply feature extraction technique use kaggle mushroom classification dataset example objective try predict mushroom poisonous look give feature code use post available kaggle github account '],\n",
       "      dtype='<U318')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = np.array([str_text1, str_text2, str_text3])\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bag_of_words(document: np.array):\n",
    "    return count.fit_transform(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = get_bag_of_words(document=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>account</th>\n",
       "      <th>aim</th>\n",
       "      <th>andor</th>\n",
       "      <th>another</th>\n",
       "      <th>apply</th>\n",
       "      <th>article</th>\n",
       "      <th>available</th>\n",
       "      <th>classification</th>\n",
       "      <th>code</th>\n",
       "      <th>...</th>\n",
       "      <th>selection</th>\n",
       "      <th>set</th>\n",
       "      <th>summarise</th>\n",
       "      <th>summarize</th>\n",
       "      <th>technique</th>\n",
       "      <th>try</th>\n",
       "      <th>use</th>\n",
       "      <th>version</th>\n",
       "      <th>walk</th>\n",
       "      <th>way</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  account  aim  andor  another  apply  article  available  \\\n",
       "0     1        0    1      0        0      0        0          0   \n",
       "1     0        0    1      1        1      0        1          0   \n",
       "2     0        1    0      0        0      1        1          1   \n",
       "\n",
       "   classification  code  ...  selection  set  summarise  summarize  technique  \\\n",
       "0               0     0  ...          0    3          1          1          0   \n",
       "1               0     0  ...          4    0          0          0          1   \n",
       "2               1     1  ...          0    0          0          0          1   \n",
       "\n",
       "   try  use  version  walk  way  \n",
       "0    0    0        1     0    1  \n",
       "1    0    1        0     0    0  \n",
       "2    1    2        0     1    0  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bg = pd.DataFrame(bag_of_words.toarray(), columns=count.get_feature_names())\n",
    "df_bg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(document: np.array):\n",
    "    return tfidf.fit_transform(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_ = get_tfidf(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x55 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 73 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>account</th>\n",
       "      <th>aim</th>\n",
       "      <th>andor</th>\n",
       "      <th>another</th>\n",
       "      <th>apply</th>\n",
       "      <th>article</th>\n",
       "      <th>available</th>\n",
       "      <th>classification</th>\n",
       "      <th>code</th>\n",
       "      <th>...</th>\n",
       "      <th>selection</th>\n",
       "      <th>set</th>\n",
       "      <th>summarise</th>\n",
       "      <th>summarize</th>\n",
       "      <th>technique</th>\n",
       "      <th>try</th>\n",
       "      <th>use</th>\n",
       "      <th>version</th>\n",
       "      <th>walk</th>\n",
       "      <th>way</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.128883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.38665</td>\n",
       "      <td>0.128883</td>\n",
       "      <td>0.128883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098175</td>\n",
       "      <td>0.129089</td>\n",
       "      <td>0.129089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516355</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.284603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187109</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able   account       aim     andor   another     apply   article  \\\n",
       "0  0.128883  0.000000  0.098019  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.098175  0.129089  0.129089  0.000000  0.098175   \n",
       "2  0.000000  0.187109  0.000000  0.000000  0.000000  0.187109  0.142301   \n",
       "\n",
       "   available  classification      code  ...  selection      set  summarise  \\\n",
       "0   0.000000        0.000000  0.000000  ...   0.000000  0.38665   0.128883   \n",
       "1   0.000000        0.000000  0.000000  ...   0.516355  0.00000   0.000000   \n",
       "2   0.187109        0.187109  0.187109  ...   0.000000  0.00000   0.000000   \n",
       "\n",
       "   summarize  technique       try       use   version      walk       way  \n",
       "0   0.128883   0.000000  0.000000  0.000000  0.128883  0.000000  0.128883  \n",
       "1   0.000000   0.098175  0.000000  0.098175  0.000000  0.000000  0.000000  \n",
       "2   0.000000   0.142301  0.187109  0.284603  0.000000  0.187109  0.000000  \n",
       "\n",
       "[3 rows x 55 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame(tfidf_.toarray(), columns=tfidf.get_feature_names())\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47d7a3528df19f6d7d5b443030394cb1b3b5540a28bb20dc453d994d1e3e4878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
